<Title>Fully Connected Layer/Linear Layer</Title>
<Tagline>The Token's Final Destination</Tagline>

Right before calculating the output probabilities, all the information gathered in earlier steps of the transformers architecture will pass through what is known as a fully connected layer, or a linear layer. This layer will have a batch size, number of inputs, and number of outputs. It's basically just a perceptron...but placed at the end of a Large Language Model.

![Fully Connected Layer](/images/fc.webp "Fully Connected Layer")