# imatrix: GGUF Subset Packs a Punch

This is a type of quantization which stems from llama.cpp and GGUF. It adds an "importance matrix" in order to make really small quants much more useful. This makes heavy quanting much more useful than it was before.

You can find the docs for imatrix quanting here: https://github.com/ggerganov/llama.cpp/tree/master/examples/imatrix